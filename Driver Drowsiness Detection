import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.callbacks import EarlyStopping
from scipy.signal import butter, lfilter

from mne.filter import notch_filter
from sklearn.metrics import classification_report
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics import confusion_matrix

# Load the data
data = pd.read_csv('C:/Users/hp/Desktop/acquiredDataset.csv')

# Assuming that your data has a 'classification' column and EEG data columns named 'eeg1', 'eeg2', etc.
X = data.drop('classification', axis=1).values
y = data['classification'].values

# Define the sample rate and the low and high cutoff frequencies
fs = 128.0
lowcut = 0.5
highcut = 50.0

# Function for highpass filter
def butter_highpass(cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='high', analog=False)
    return b, a

def butter_highpass_filter(data, cutoff, fs, order=5):
    b, a = butter_highpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y

# Function for lowpass filter
def butter_lowpass(cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return b, a

def butter_lowpass_filter(data, cutoff, fs, order=5):
    b, a = butter_lowpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y

# Apply the highpass filter
X = butter_highpass_filter(X, lowcut, fs, order=6)

# Apply the lowpass filter
X = butter_lowpass_filter(X, highcut, fs, order=6)

# Define the power line frequency
freq = 60.0

# Apply the notch filter
X = notch_filter(X, fs, freq)

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Create a Sequential model
model = Sequential()

# Add an input layer and a hidden layer
model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))
model.add(Dropout(0.5))

# Add more hidden layers
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))

# Add a output layer
model.add(Dense(1, activation='sigmoid'))

# Compile the model with a different optimizer and a learning rate
from keras.optimizers import RMSprop
model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Define early stopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)

# Train the model with more epochs and a different batch size
model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[es])

# ... (rest of your code)

# Predict the test set results
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)

# Calculate Precision
precision = precision_score(y_test, y_pred)

# Calculate Recall
recall = recall_score(y_test, y_pred)

# Calculate F1 Score
f1 = f1_score(y_test, y_pred)

# Calculate ROC AUC
roc_auc = roc_auc_score(y_test, y_pred)

print('Precision: %.2f' % precision)
print('Recall: %.2f' % recall)
print('F1 Score: %.2f' % f1)
print('AUC-ROC: %.2f' % roc_auc)

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)

# Print the Precision, Recall, F1 score, and Accuracy
print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))
print('Accuracy:', accuracy)

# Create confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
print('Confusion Matrix:\n', conf_mat)

import matplotlib.pyplot as plt
import seaborn as sns

# Create confusion matrixc
conf_mat = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

from sklearn.metrics import roc_curve, auc
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()
