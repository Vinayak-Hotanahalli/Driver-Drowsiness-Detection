# EEG Data Classification Using Neural Networks
# This script processes EEG data, filters it to remove noise, 
# and trains a neural network to classify the data based on 
# specified target labels.

# Import required libraries
import pandas as pd  # For data manipulation
from sklearn.model_selection import train_test_split  # To split data into train and test sets
from sklearn.preprocessing import StandardScaler  # For scaling data
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score
from scipy.signal import butter, lfilter  # For signal filtering
from mne.filter import notch_filter  # For notch filtering
from keras.models import Sequential  # For building the neural network model
from keras.layers import Dense, Dropout  # For defining layers in the model
from keras.callbacks import EarlyStopping  # To prevent overfitting during training
from keras.optimizers import RMSprop  # For model optimization
import matplotlib.pyplot as plt  # For plotting results
import seaborn as sns  # For heatmap visualization

# Load the EEG data
data = pd.read_csv('C:/Users/hp/Desktop/acquiredDataset.csv')
X = data.drop('classification', axis=1).values  # Features
y = data['classification'].values  # Target labels

# Define signal filtering functions

# Highpass filter function
def butter_highpass(cutoff, fs, order=5):
    nyq = 0.5 * fs  # Nyquist frequency
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='high', analog=False)
    return b, a

# Function to apply highpass filter
def butter_highpass_filter(data, cutoff, fs, order=5):
    b, a = butter_highpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y

# Lowpass filter function
def butter_lowpass(cutoff, fs, order=5):
    nyq = 0.5 * fs
    normal_cutoff = cutoff / nyq
    b, a = butter(order, normal_cutoff, btype='low', analog=False)
    return b, a

# Function to apply lowpass filter
def butter_lowpass_filter(data, cutoff, fs, order=5):
    b, a = butter_lowpass(cutoff, fs, order=order)
    y = lfilter(b, a, data)
    return y

# Apply filtering
fs = 256  # Sampling frequency
X = butter_highpass_filter(X, 0.5, fs)
X = butter_lowpass_filter(X, 50, fs)
freq = 60.0  # Frequency for notch filtering
X = notch_filter(X, fs, freq)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale data to standardize input for neural network
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Build the neural network model
model = Sequential([
    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')  # Sigmoid for binary classification
])

# Compile the model with optimizer and loss function
model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

# Early stopping to prevent overfitting
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2, callbacks=[es])

# Model evaluation on test set
y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)  # Convert probabilities to binary output

# Performance metrics
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)

# Print classification report
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))

# Confusion matrix
conf_mat = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 7))
sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_pred)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()
